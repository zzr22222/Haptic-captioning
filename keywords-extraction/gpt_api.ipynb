{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2691"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "2691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful linguistic assistant.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Extract emotional, sensational and metaphor keywords from the corresponding texts below: 1. You need to first understand the meaning of the sentence before selection. \\n2. Remain the negative or positive meaning of the sentences. \\n3. Only select ADJ and NOUN keywords.  \\n4. Please follow the answer form \\\"Emotional, sensational and metaphor keywords:\\\"\\n5. Remove words “emotional” and “sensational”.\\n\\nText1 : No, but I think that is largely because it's quite weak, rather than the pattern itself. No, not yet. It's quite calming, really. Honestly, because of the white noise, it kind of sounds like a beach, and that's the only thing I can have in my head. I don't really know. It's maybe pulsating. I don't know. Again, it's not massively put me up or down, to be honest. I think if it was a stronger pulse, then maybe. No, but again, I think that's partially more to do with the actual fact that I am here with a friend with white noise. It's not a very distressing situation. Quite pleasant, really. I don't know.\\nText2: I'm not sure I am feeling this one. It doesn't feel like there's as much of a pulse as the last one, maybe. I don't know. I don't know if it's maybe because this one feels maybe more active or something, and I'm not feeling as much in the pulsing, but maybe more just of a general tingling or something. I don't know. I'm not feeling it super strong, so it's hard to say. It's almost like you're petting a cat or something, but a cat with not very long hair. And it was robotic. It's pleasant. I don't know. This one feels a bit more familiar, I would say.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Emotional, sensational and metaphor keywords:\\nText1: quite weak,quite calming,beach,pulsating,stronger pulse,distressing,Quite pleasant\\n\\nText2: pulse,active,pulsing,tingling,not strong,petting a cat,robotic,pleasant\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\":\"\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=0.1,\n",
    "  max_tokens=840,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotional, sensational and metaphor keywords:\n",
      "Text1: stronger, excited, satisfied, nice, pleasing, beach, white noise, calming, pulsating, alien feeling, technological feeling, massage\n",
      "Text2: not feeling, rhythm, tingling, general, robotic, familiar\n",
      "Text3: regular, pulse, gentle vibrations, fancy alarm clock, direct, distress, regular, gentle\n",
      "Text4: urgent, strong, alarm, actions afoot, favorite, high-pressure situation\n",
      "Text5: slower, heartbeat, watering system, regular, soft, indirect\n",
      "Text6: regular, intense, alarm, jarring, nice intensity, pleasing, rhythmic, tactile sensation\n",
      "Text7: not much, rhythmic, soft, constant, unnerving, indirect\n",
      "Text8: [empty]\n",
      "Text9: not much, similar\n",
      "Text10: train, jogging, rhythmic, pulsating, up-beat, not alarming\n",
      "Text11: train, settling, soothing, rhythmic, positive, remote controller, not in danger\n",
      "Text12: strong, shaving, constant, urgent, techno, high-pressure situation, not relaxing\n",
      "Text13: printer, shooting out pages, pleasing, mundane, rhythmic, fast, passenger, not catching\n",
      "Text14: not much, slow, bored, not distressed, background noise, boring, early 2000s printer\n",
      "Text15: creaky, seesaw, knife-edge, uncomfortable\n",
      "Text16: similar, balloon, squeaky, distressed, numb\n",
      "Text17: waiting, smooth, glass, fingerprint button on an iPhone, quiet\n",
      "Text18: similar, fingerprint button on an iPhone, alarm clock\n",
      "Text19: smooth, water, boring, not distressed, not dominant\n",
      "Text20: smoother, icing sugar, soft, smooth pen, nice\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Text1\n",
      "Processed Text2\n",
      "Processed Text3\n",
      "Processed Text4\n",
      "Processed Text5\n",
      "Processed Text6\n",
      "Processed Text7\n",
      "Processed Text8\n",
      "Processed Text9\n",
      "Processed Text10\n",
      "Processed Text11\n",
      "Processed Text12\n",
      "Processed Text13\n",
      "Processed Text14\n",
      "Processed Text15\n",
      "Processed Text16\n",
      "Processed Text17\n",
      "Processed Text18\n",
      "Processed Text19\n",
      "Processed Text20\n",
      "Processed Text21\n",
      "Processed Text22\n",
      "Processed Text23\n",
      "Processed Text24\n",
      "Processed Text25\n",
      "Processed Text26\n",
      "Processed Text27\n",
      "Processed Text28\n",
      "Processed Text29\n",
      "Processed Text30\n",
      "Processed Text31\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[39m# 可选：打印进度\u001b[39;00m\n\u001b[1;32m     59\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mProcessed Text\u001b[39m\u001b[39m{\u001b[39;00midx\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 61\u001b[0m         time\u001b[39m.\u001b[39msleep(\u001b[39m5\u001b[39m)\n\u001b[1;32m     63\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll texts processed and responses saved to gpt_ans.csv!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "# 配置API密钥\n",
    "openai.api_key = \"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\"\n",
    "\n",
    "# 读取Ptext.txt文件\n",
    "with open('/Users/zhaozirui/Desktop/ASU-visiting student/9.1/Ptext.txt', 'r', encoding='utf-8') as file:\n",
    "    texts = file.read().split('\\n')\n",
    "\n",
    "# 创建或打开gpt_ans.csv文件，准备写入数据\n",
    "with open('gpt_ans2.csv', 'a', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    # 写入标题行\n",
    "    writer.writerow(['Text No', 'Response'])\n",
    "\n",
    "    for idx, text in enumerate(texts, start=1):\n",
    "        if not text.strip():\n",
    "            continue  # 跳过空行\n",
    "        \n",
    "        # 创建API请求消息结构\n",
    "        messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"You are a helpful linguistic assistant.\\n\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Extract keywords including sensational, emotional, metaphoric, and usage examples from the corresponding texts below: \\n1. You need to first understand the meaning of the sentence before selection. \\n2. Remain the negative or positive meaning of the sentences. \\n3. Only select ADJ and NOUN keywords.\\n4. Must Remove words \\\"emotional\\\", \\\"sensational\\\", \\\"emotion\\\", \\\"sensation\\\", \\\"feeling\\\", and their derivatives.\\n\\nText: No, but I think that is largely because it's quite weak, rather than the pattern itself. No, not yet. It's quite calming, really. Honestly, because of the white noise, it kind of sounds like a beach, and that's the only thing I can have in my head. I don't really know. It's maybe pulsating. I don't know. Again, it's not massively put me up or down, to be honest. I think if it was a stronger pulse, then maybe. No, but again, I think that's partially more to do with the actual fact that I am here with a friend with white noise. It's not a very distressing situation. Quite pleasant, really. I don't know.\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"weak,calming,white noise,beach,pulsating,put me up or down,stronger pulse,distressing,pleasant\"\n",
    "    },\n",
    "        {\n",
    "         \"role\": \"user\",\n",
    "         \"content\":text\n",
    "        }\n",
    "        ]\n",
    "        \n",
    "        # 发起API调用\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=messages,\n",
    "            temperature=0,\n",
    "            max_tokens=1024,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0\n",
    "        )\n",
    "        \n",
    "        # 提取响应并写入CSV文件\n",
    "        answer = response.choices[0].message['content']\n",
    "        writer.writerow([answer])\n",
    "\n",
    "        # 可选：打印进度\n",
    "        print(f\"Processed Text{idx}\")\n",
    "        \n",
    "        time.sleep(5)\n",
    "\n",
    "print(\"All texts processed and responses saved to gpt_ans.csv!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件生成完毕!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 读取csv文件\n",
    "ptext_df = pd.read_csv('/Users/zhaozirui/Desktop/ASU-visiting student/8.25/Ptext.csv')\n",
    "cleaned_manual_df = pd.read_csv('/Users/zhaozirui/Desktop/ASU-visiting student/8.25/Cleaned_Manual_dataset.csv')\n",
    "\n",
    "# 检查两个csv文件行数是否相同，如果不同则输出提示并退出\n",
    "if len(ptext_df) != len(cleaned_manual_df):\n",
    "    print(\"两个CSV文件的行数不同!\")\n",
    "    exit()\n",
    "\n",
    "# 打开jsonl文件并按照要求写入内容\n",
    "with open('output.jsonl', 'w') as f:\n",
    "    for i in range(len(ptext_df)):\n",
    "        entry = {\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful linguistic assistant. Extract keywords including sensational, emotional, metaphoric, and usage examples from the corresponding texts below: 1. You need to first understand the meaning of the sentence before selection. 2. Remain the negative or positive meaning of the sentences. 3. Only select ADJ and NOUN keywords. 4. Must Remove words \\\"emotional\\\", \\\"sensational\\\", \\\"emotion\\\", \\\"sensation\\\", \\\"feeling\\\", and their derivatives.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": ptext_df['Text'].iloc[i]\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": cleaned_manual_df['Tags'].iloc[i]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(entry))\n",
    "        f.write('\\n')  # 写入换行符以创建新的jsonl记录\n",
    "\n",
    "print(\"文件生成完毕!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据已成功分为训练集和测试集!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 读取原始的jsonl文件\n",
    "with open('output.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    entries = [json.loads(line) for line in lines]\n",
    "\n",
    "# 使用train_test_split将数据分为训练集和测试集\n",
    "train_data, test_data = train_test_split(entries, train_size=0.35, random_state=44)  # 设置随机种子以确保结果可重复\n",
    "\n",
    "# 保存训练集到train.jsonl\n",
    "with open('train.jsonl', 'w') as train_file:\n",
    "    for entry in train_data:\n",
    "        train_file.write(json.dumps(entry))\n",
    "        train_file.write('\\n')\n",
    "\n",
    "# 保存测试集到test.jsonl\n",
    "with open('test.jsonl', 'w') as test_file:\n",
    "    for entry in test_data:\n",
    "        test_file.write(json.dumps(entry))\n",
    "        test_file.write('\\n')\n",
    "\n",
    "print(\"数据已成功分为训练集和测试集!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-MlWIQJ1j3wbtZWa695cXX9kp at 0x17d3be8d0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-MlWIQJ1j3wbtZWa695cXX9kp\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 81290,\n",
       "  \"created_at\": 1694114875,\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "openai.api_key = \"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\"\n",
    "openai.File.create(\n",
    "  file=open('/Users/zhaozirui/spacy_nlp/.venv/train.jsonl'),\n",
    "  purpose='fine-tune',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<File file id=file-MlWIQJ1j3wbtZWa695cXX9kp at 0x17c82f5f0> JSON: {\n",
       "  \"object\": \"file\",\n",
       "  \"id\": \"file-MlWIQJ1j3wbtZWa695cXX9kp\",\n",
       "  \"purpose\": \"fine-tune\",\n",
       "  \"filename\": \"file\",\n",
       "  \"bytes\": 81290,\n",
       "  \"created_at\": 1694114875,\n",
       "  \"status\": \"uploaded\",\n",
       "  \"status_details\": null\n",
       "}"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.File.retrieve('file-MlWIQJ1j3wbtZWa695cXX9kp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-XQ68MkJuPsRsuXoQ4mLc284T at 0x17c2a3e90> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-XQ68MkJuPsRsuXoQ4mLc284T\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1694114994,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-S8weXgSKTPJxBRjQZlBZZ2Ci\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"created\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-MlWIQJ1j3wbtZWa695cXX9kp\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.create(\n",
    "  training_file='file-MlWIQJ1j3wbtZWa695cXX9kp',\n",
    "  model='gpt-3.5-turbo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-XQ68MkJuPsRsuXoQ4mLc284T at 0x17c2a2f90> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-XQ68MkJuPsRsuXoQ4mLc284T\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1694114994,\n",
       "  \"finished_at\": 1694115417,\n",
       "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:arizona-state-university::7wF6AmyK\",\n",
       "  \"organization_id\": \"org-S8weXgSKTPJxBRjQZlBZZ2Ci\",\n",
       "  \"result_files\": [\n",
       "    \"file-T2dgqkSfMPeNBBOLDNtXtPk6\"\n",
       "  ],\n",
       "  \"status\": \"succeeded\",\n",
       "  \"validation_file\": null,\n",
       "  \"training_file\": \"file-MlWIQJ1j3wbtZWa695cXX9kp\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 3\n",
       "  },\n",
       "  \"trained_tokens\": 53619,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##运行这个来检查！！！\n",
    "openai.FineTuningJob.retrieve('ftjob-XQ68MkJuPsRsuXoQ4mLc284T')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x17c0bbf50> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-TSj4XAF6U39ZNDPDCZGgXkdl\",\n",
       "      \"created_at\": 1694114994,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Fine tuning job started\",\n",
       "      \"data\": null,\n",
       "      \"type\": \"message\"\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job.event\",\n",
       "      \"id\": \"ftevent-zReP7ah4a3GpO852QEQB2SZo\",\n",
       "      \"created_at\": 1694114994,\n",
       "      \"level\": \"info\",\n",
       "      \"message\": \"Created fine-tuning job: ftjob-XQ68MkJuPsRsuXoQ4mLc284T\",\n",
       "      \"data\": {},\n",
       "      \"type\": \"message\"\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai.FineTuningJob.list_events(id='ftjob-XQ68MkJuPsRsuXoQ4mLc284T', limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已从test.jsonl中移除role为assistant的部分!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# 读取test.jsonl文件内容\n",
    "with open('train.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    entries = [json.loads(line) for line in lines]\n",
    "\n",
    "# 移除role为assistant的部分\n",
    "for entry in entries:\n",
    "    entry[\"messages\"] = [message for message in entry[\"messages\"] if message[\"role\"] != \"assistant\"]\n",
    "\n",
    "# 将修改后的内容重新写入test.jsonl文件\n",
    "with open('train_remain.jsonl', 'w') as file:\n",
    "    for entry in entries:\n",
    "        file.write(json.dumps(entry))\n",
    "        file.write('\\n')\n",
    "\n",
    "print(\"已从test.jsonl中移除role为assistant的部分!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.jsonl文件已成功修改!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 从Ptext.csv中读取数据\n",
    "df = pd.read_csv('/Users/zhaozirui/Desktop/ASU-visiting student/8.25/Ptext.csv')\n",
    "\n",
    "# 读取test.jsonl文件内容\n",
    "with open('train_remain.jsonl', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    entries = [json.loads(line) for line in lines]\n",
    "\n",
    "# 对每一条记录进行修改\n",
    "for entry in entries:\n",
    "    user_content = next((message[\"content\"] for message in entry[\"messages\"] if message[\"role\"] == \"user\"), None)\n",
    "    \n",
    "    if user_content:\n",
    "        # 找到对应的Participants和Signal\n",
    "        matched_row = df[df['Text'] == user_content].iloc[0]\n",
    "        entry[\"Participants\"] = matched_row[\"Participants\"]\n",
    "        entry[\"Signal\"] = matched_row[\"Signal\"]\n",
    "        \n",
    "        # 修改role为system的content内容\n",
    "        for message in entry[\"messages\"]:\n",
    "            if message[\"role\"] == \"system\":\n",
    "                message[\"content\"] = \"Extract keywords including sensational, emotional, metaphoric, and usage examples from the corresponding texts below.\"\n",
    "\n",
    "# 定义一个自定义序列化函数\n",
    "def default_serializer(o):\n",
    "    if isinstance(o, pd.Int64Dtype().type):  # 检查是否为int64\n",
    "        return int(o)  # 将int64转换为Python原生的int\n",
    "    raise TypeError(f'Object of type {o.__class__.__name__} is not JSON serializable')\n",
    "\n",
    "\n",
    "# 将修改后的内容重新写入test.jsonl文件\n",
    "with open('train_remain.jsonl', 'w') as file:\n",
    "    for entry in entries:\n",
    "        file.write(json.dumps(entry, default=default_serializer))  # 在这里使用自定义序列化函数\n",
    "        file.write('\\n')\n",
    "\n",
    "print(\"test.jsonl文件已成功修改!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"content\": \"pinky,picking,uneven,not equal,bad,not nice,intense,not a good time,Bad,not sad,not angry,bad emotion Annoyance,On even,sloppy,annoyed,uncomfortable\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "completion = openai.ChatCompletion.create(\n",
    "model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vgj0H0G', # Your Model Id\n",
    "messages=[{\"role\": \"system\", \"content\": \"Extract keywords including sensational, emotional, metaphoric, and usage examples from the corresponding texts below.\"}, \n",
    "          {\"role\": \"user\", \"content\": \"Maybe something on the first two. Yes, there's my pinky picking something up. Definitely got something. I don't like this one. Why? It feels uneven. The vibrations just aren't equal to each other, and that just doesn't feel good. It's more intense than the others, but not in a nice way. Nothing springing to mind. I'm not having a good time, I would say. Bad. I'm not sad. I'm not angry. What's a bad emotion? Annoyance; get yourself together. Why are you so on even? Yes, someone who is sloppy, messy. I'm annoyed at you. And you're making me uncomfortable.\"}]\n",
    "\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m entry \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(line)\n\u001b[1;32m     13\u001b[0m \u001b[39m# 使用文件中的messages调用OpenAI API\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     15\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mft:gpt-3.5-turbo-0613:arizona-state-university::7vgj0H0G\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# 您的模型ID\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vuoVnmH',  # 您的模型ID\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vvXnl8w', \u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vwKnBy9',\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vwzkGoe',\u001b[39;49;00m\n\u001b[1;32m     20\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vyAL5wx',\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7w0n7EfQ',\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7w1qWshb',\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7wDxFkdc',\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39m#model='ft:gpt-3.5-turbo-0613:arizona-state-university::7wF6AmyK',\u001b[39;49;00m\n\u001b[1;32m     25\u001b[0m \n\u001b[1;32m     26\u001b[0m \n\u001b[1;32m     27\u001b[0m     messages\u001b[39m=\u001b[39;49mentry[\u001b[39m\"\u001b[39;49m\u001b[39mmessages\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m \u001b[39m# 获取模型的回复\u001b[39;00m\n\u001b[1;32m     31\u001b[0m response \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/openai/api_resources/chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/openai/api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    279\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[1;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[1;32m    290\u001b[0m         url,\n\u001b[1;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    297\u001b[0m     )\n\u001b[1;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[1;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/openai/api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[0;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    597\u001b[0m         method,\n\u001b[1;32m    598\u001b[0m         abs_url,\n\u001b[1;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[1;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[1;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[1;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[1;32m    605\u001b[0m     )\n\u001b[1;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    498\u001b[0m     )\n\u001b[1;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    791\u001b[0m     conn,\n\u001b[1;32m    792\u001b[0m     method,\n\u001b[1;32m    793\u001b[0m     url,\n\u001b[1;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    795\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    796\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    798\u001b[0m     retries\u001b[39m=\u001b[39;49mretries,\n\u001b[1;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39;49mresponse_conn,\n\u001b[1;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39;49mpreload_content,\n\u001b[1;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39;49mdecode_content,\n\u001b[1;32m    802\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mresponse_kw,\n\u001b[1;32m    803\u001b[0m )\n\u001b[1;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[1;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m~/spacy_nlp/.venv/lib/python3.11/site-packages/urllib3/connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:1378\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1376\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1377\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1378\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1379\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1380\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    707\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.11/3.11.4_1/Frameworks/Python.framework/Versions/3.11/lib/python3.11/ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# 加载fine_tune_res.csv到一个DataFrame\n",
    "df = pd.read_csv(\"fine_tune_res_remain.csv\")\n",
    "i=1\n",
    "# 从test.jsonl文件中读取每一行\n",
    "with open('train_remain.jsonl', 'r') as file:\n",
    "    for line in file:\n",
    "        entry = json.loads(line)\n",
    "\n",
    "        # 使用文件中的messages调用OpenAI API\n",
    "        completion = openai.ChatCompletion.create(\n",
    "            model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vgj0H0G',  # 您的模型ID\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vuoVnmH',  # 您的模型ID\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vvXnl8w', \n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vwKnBy9',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vwzkGoe',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7vyAL5wx',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7w0n7EfQ',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7w1qWshb',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7wDxFkdc',\n",
    "            #model='ft:gpt-3.5-turbo-0613:arizona-state-university::7wF6AmyK',\n",
    "\n",
    "\n",
    "            messages=entry[\"messages\"]\n",
    "        )\n",
    "\n",
    "        # 获取模型的回复\n",
    "        response = completion.choices[0].message[\"content\"]\n",
    "\n",
    "        # Add new data to the DataFrame\n",
    "        new_index = df.shape[0]\n",
    "        df.loc[new_index] = [entry[\"Participants\"], entry[\"Signal\"], response]\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        df.to_csv(\"fine_tune_res_remain.csv\", index=False)\n",
    "        print(i)\n",
    "        i=i+1\n",
    "\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义输入和输出文件名称\n",
    "input_filename = 'fine_tune_res_remain.csv'\n",
    "output_filename = 'fine_tune_res_remain.csv'\n",
    "\n",
    "# input_filename = '/Users/zhaozirui/Desktop/ASU-visiting student/8.25/Cleaned_Manual_dataset.csv'\n",
    "# output_filename = '/Users/zhaozirui/Desktop/ASU-visiting student/8.25/Cleaned_Manual_dataset.csv'\n",
    "\n",
    "# 读取文件内容\n",
    "with open(input_filename, 'r') as infile:\n",
    "    content = infile.read()\n",
    "\n",
    "# 替换逗号后的空格\n",
    "cleaned_content1 = content.replace(', ', ',')\n",
    "cleaned_content2 = cleaned_content1.replace(' ,', ',')\n",
    "cleaned_content3 = cleaned_content2.replace(' , ', ',')\n",
    "cleaned_content4 = cleaned_content3.replace('.', ',')\n",
    "cleaned_content5 = cleaned_content4.rstrip((' '))\n",
    "\n",
    "\n",
    "# 写入到新的文件\n",
    "with open(output_filename, 'w') as outfile:\n",
    "    outfile.write(cleaned_content5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 1 - Average Precision: 0.755691391941392\n",
      "Participant 1 - Average Recall: 0.6946154029793735\n",
      "Participant 1 - Average F1 Score: 0.7204846223652273\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 2 - Average Precision: 0.7226731601731603\n",
      "Participant 2 - Average Recall: 0.7570368867243868\n",
      "Participant 2 - Average F1 Score: 0.7343390634992804\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 3 - Average Precision: 0.7192573051948052\n",
      "Participant 3 - Average Recall: 0.7285511363636364\n",
      "Participant 3 - Average F1 Score: 0.7155252458361474\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 4 - Average Precision: 0.7813427891552892\n",
      "Participant 4 - Average Recall: 0.7696993978243979\n",
      "Participant 4 - Average F1 Score: 0.7705979910484638\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 5 - Average Precision: 0.6723797240341359\n",
      "Participant 5 - Average Recall: 0.6368036929857582\n",
      "Participant 5 - Average F1 Score: 0.6459789986623609\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 6 - Average Precision: 0.7005970132808369\n",
      "Participant 6 - Average Recall: 0.665533200459671\n",
      "Participant 6 - Average F1 Score: 0.6755382000368388\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 7 - Average Precision: 0.7129945693388998\n",
      "Participant 7 - Average Recall: 0.6956326750734646\n",
      "Participant 7 - Average F1 Score: 0.7007371302436006\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 8 - Average Precision: 0.7077142526591055\n",
      "Participant 8 - Average Recall: 0.7008128736481097\n",
      "Participant 8 - Average F1 Score: 0.6959156942648714\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 9 - Average Precision: 0.7520044191919192\n",
      "Participant 9 - Average Recall: 0.7467757936507936\n",
      "Participant 9 - Average F1 Score: 0.7428452185443369\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 10 - Average Precision: 0.7273538961038962\n",
      "Participant 10 - Average Recall: 0.6504315129315129\n",
      "Participant 10 - Average F1 Score: 0.6763600014844715\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 11 - Average Precision: 0.6566346847596847\n",
      "Participant 11 - Average Recall: 0.7202361874236874\n",
      "Participant 11 - Average F1 Score: 0.6772276516641925\n",
      "-----\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "16\n",
      "Participant 12 - Average Precision: 0.6394784035409036\n",
      "Participant 12 - Average Recall: 0.6770181309703369\n",
      "Participant 12 - Average F1 Score: 0.6409731989457925\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the CSV files\n",
    "pred_filepath = \"/Users/zhaozirui/spacy_nlp/.venv/fine_tune_res.csv\"\n",
    "true_filepath = \"Cleaned_Manual_dataset.csv\"\n",
    "\n",
    "y_pred_df = pd.read_csv(pred_filepath)\n",
    "y_true_df = pd.read_csv(true_filepath)\n",
    "\n",
    "# Unique participants in y_pred_df\n",
    "unique_participants = y_pred_df['Participants'].unique()\n",
    "\n",
    "for participant in unique_participants:\n",
    "    \n",
    "    # Get unique signals for current participant in y_pred_df\n",
    "    unique_signals = y_pred_df[y_pred_df['Participants'] == participant]['Signal'].unique()\n",
    "    \n",
    "    print(unique_signals)\n",
    "\n",
    "    # Lists to store average precision, recall, and F1 score for the current participant\n",
    "    participant_precisions = []\n",
    "    participant_recalls = []\n",
    "    participant_f1s = []\n",
    "    \n",
    "    for signal in unique_signals:\n",
    "        # Filter rows based on current participant and signal\n",
    "        y_pred_signal = y_pred_df[(y_pred_df['Participants'] == participant) & (y_pred_df['Signal'] == signal)]['Tags'].values\n",
    "        y_true_signal = y_true_df[(y_true_df['Participants'] == participant) & (y_true_df['Signal'] == signal)]['Tags'].values\n",
    "\n",
    "        # Initialize lists to store precision, recall, and F1 score for each row\n",
    "        all_precisions = []\n",
    "        all_recalls = []\n",
    "        all_f1s = []\n",
    "\n",
    "        for y_pred, y_true in zip(y_pred_signal, y_true_signal):\n",
    "            \n",
    "            # Convert the strings into lists\n",
    "            y_true = y_true.lower().split(',')\n",
    "            y_pred = y_pred.lower().split(',')\n",
    "\n",
    "            # Convert the labels into binary format\n",
    "            unique_labels = set(y_true + y_pred)\n",
    "            y_true_binary = [1 if label in y_true else 0 for label in unique_labels]\n",
    "            y_pred_binary = [1 if label in y_pred else 0 for label in unique_labels]\n",
    "\n",
    "            # Calculate and store precision, recall, and F1 score for the current row\n",
    "            all_precisions.append(precision_score(y_true_binary, y_pred_binary))\n",
    "            all_recalls.append(recall_score(y_true_binary, y_pred_binary))\n",
    "            all_f1s.append(f1_score(y_true_binary, y_pred_binary))\n",
    "            \n",
    "        # Store the average scores for the current signal under the current participant\n",
    "        participant_precisions.extend(all_precisions)\n",
    "        participant_recalls.extend(all_recalls)\n",
    "        participant_f1s.extend(all_f1s)\n",
    "\n",
    "    # Calculate the average precision, recall, and F1 score for the current participant\n",
    "    \n",
    "    print(len(participant_precisions))\n",
    "    \n",
    "    avg_precision = sum(participant_precisions) / len(participant_precisions)\n",
    "    avg_recall = sum(participant_recalls) / len(participant_recalls)\n",
    "    avg_f1 = sum(participant_f1s) / len(participant_f1s)\n",
    "    \n",
    "    print(f\"Participant {participant} - Average Precision:\", avg_precision)\n",
    "    print(f\"Participant {participant} - Average Recall:\", avg_recall)\n",
    "    print(f\"Participant {participant} - Average F1 Score:\", avg_f1)\n",
    "    print(\"-----\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
